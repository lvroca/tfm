{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importación librerías\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from prophet import Prophet\n",
    "from sklearn import *\n",
    "from sklearn.ensemble import *\n",
    "import json\n",
    "from pycaret.containers.models.time_series import BaseCdsDtForecaster\n",
    "from sktime.transformations.series.summarize import WindowSummarizer\n",
    "from sktime.forecasting.croston import Croston\n",
    "from lightgbm import LGBMRegressor\n",
    "from sktime.forecasting.arima import ARIMA, AutoARIMA\n",
    "from scipy.stats import uniform\n",
    "from mango import Tuner\n",
    "from sktime.forecasting.base import ForecastingHorizon\n",
    "from sklearn.linear_model import OrthogonalMatchingPursuit,LinearRegression\n",
    "from catboost import CatBoostRegressor\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GRU, Dense, Dropout,BatchNormalization\n",
    "import keras_tuner as kt\n",
    "from tensorflow. keras.optimizers import Adam\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lectura de datos\n",
    "df = pd.read_excel(\"reporte_diario_campaña_limpio.xlsx\").drop(columns='Unnamed: 0')\n",
    "festivos=pd.read_excel(\"prophet_festivos.xlsx\")\n",
    "entrenamiento_calls = pd.read_excel(\"validacion_diaria_calls.xlsx\").drop(columns='Unnamed: 0')\n",
    "entrenamiento_aht = pd.read_excel(\"validacion_diaria_aht.xlsx\").drop(columns='Unnamed: 0')\n",
    "with open('diccionario_calls.txt', 'r') as file:\n",
    "    contenido = file.read()\n",
    "diccionario_calls = json.loads(contenido)\n",
    "for key in diccionario_calls:\n",
    "    diccionario_calls[key] = eval(diccionario_calls[key])\n",
    "with open('diccionario_aht.txt', 'r') as file:\n",
    "    contenido = file.read()\n",
    "diccionario_aht = json.loads(contenido)\n",
    "for key in diccionario_aht:\n",
    "    diccionario_aht[key] = eval(diccionario_aht[key])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición error \n",
    "def wape(y,y_pred,**kwargs):\n",
    "    wape = np.sum(np.abs(y - y_pred)) / np.sum(y)\n",
    "    return wape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamiento GRU\n",
    "def entrenamiento_gru(data,target,linea,nuevos_periodos):\n",
    "    if target == 'interpolado_real_calls':\n",
    "        features = ['año', 'mes', \"dia\", 'dia_semana', 'state_holiday']\n",
    "    else: \n",
    "        features = ['año', 'mes', \"dia\", 'dia_semana', 'state_holiday','interpolado_real_calls']\n",
    "    scaler_X = StandardScaler()\n",
    "    scaler_y = StandardScaler()\n",
    "\n",
    "    def train_test_split_by_date(data, date_column, train_end_date, test_start_date, time_step,target):\n",
    "        data[date_column] = pd.to_datetime(data[date_column])\n",
    "\n",
    "        adjusted_test_start_date = pd.to_datetime(test_start_date) - pd.Timedelta(days=time_step)\n",
    "\n",
    "        if target == 'interpolado_real_calls':\n",
    "            train_data = data[data[date_column] <= train_end_date][['año', 'mes', \"dia\", 'dia_semana', 'state_holiday',target]].dropna()\n",
    "            test_data = data[data[date_column] >= adjusted_test_start_date][['año', 'mes', \"dia\", 'dia_semana', 'state_holiday',target]].dropna()\n",
    "        else:\n",
    "            train_data = data[data[date_column] <= train_end_date][['año', 'mes', \"dia\", 'dia_semana', 'state_holiday',target,'interpolado_real_calls']].dropna()\n",
    "            test_data = data[data[date_column] >= adjusted_test_start_date][['año', 'mes', \"dia\", 'dia_semana', 'state_holiday',target,'interpolado_real_calls']].dropna()\n",
    "        return train_data, test_data\n",
    "    \n",
    "    train_data, test_data = train_test_split_by_date(data, 'fecha', '2023-12-31', '2024-01-01',14,target)\n",
    "\n",
    "    X_train, y_train = train_data[features], train_data[target]\n",
    "    X_test, y_test = test_data[features], test_data[target]\n",
    "\n",
    "    X_train_scaled = scaler_X.fit_transform(X_train)\n",
    "    y_train_scaled = scaler_y.fit_transform(y_train.values.reshape(-1, 1))\n",
    "\n",
    "    X_test_scaled = scaler_X.transform(X_test)\n",
    "    y_test_scaled = scaler_y.transform(y_test.values.reshape(-1, 1))\n",
    "\n",
    "    def create_sequences(X, y, time_steps=10):\n",
    "        Xs, ys = [], []\n",
    "        for i in range(len(X) - time_steps):\n",
    "            Xs.append(X[i:(i + time_steps)])\n",
    "            ys.append(y[i + time_steps])\n",
    "        return np.array(Xs), np.array(ys)\n",
    "\n",
    "    time_steps = 14\n",
    "    X_train_seq, y_train_seq = create_sequences(X_train_scaled, y_train_scaled, time_steps)\n",
    "    X_test_seq, y_test_seq = create_sequences(X_test_scaled, y_test_scaled, time_steps)\n",
    "    def wape_metric(y_true, y_pred):\n",
    "        return K.sum(K.abs(y_true - y_pred)) / K.sum(K.abs(y_true))\n",
    "    def build_robust_gru_model(hp):\n",
    "        model = Sequential()\n",
    "        \n",
    "        # Capas GRU\n",
    "        for i in range(hp.Int('gru_layers', 1, 3)):\n",
    "            model.add(GRU(units=hp.Int(f'gru_units_{i}', min_value=64, max_value=512, step=64),\n",
    "                        return_sequences=(i < hp.Int('gru_layers', 1, 3) - 1),\n",
    "                        recurrent_dropout=hp.Float(f'recurrent_dropout_{i}', min_value=0.0, max_value=0.3, step=0.1)))\n",
    "            model.add(Dropout(rate=hp.Float(f'dropout_{i}', min_value=0.1, max_value=0.5, step=0.1)))\n",
    "        \n",
    "        # Capa de normalización por lotes\n",
    "        model.add(BatchNormalization())\n",
    "\n",
    "        # Capas densas finales\n",
    "        for i in range(hp.Int('dense_layers', 1, 3)):\n",
    "            model.add(Dense(units=hp.Int(f'dense_units_{i}', min_value=32, max_value=256, step=32), activation='relu'))\n",
    "            model.add(Dropout(rate=hp.Float(f'dense_dropout_{i}', min_value=0.1, max_value=0.5, step=0.1)))\n",
    "\n",
    "        model.add(Dense(1))\n",
    "\n",
    "        # Compilación del modelo\n",
    "        model.compile(optimizer=Adam(hp.Float('learning_rate', min_value=1e-5, max_value=1e-2, sampling='LOG')),\n",
    "                    loss='mse',  # Seguimos utilizando 'mse' para el entrenamiento\n",
    "                    metrics=[wape_metric])  # Pero optimizamos usando WAPE\n",
    "        \n",
    "        return model\n",
    "\n",
    "    tuner = kt.RandomSearch(\n",
    "        build_robust_gru_model,\n",
    "        objective=kt.Objective('val_wape_metric', direction='min'), \n",
    "        max_trials=10,  \n",
    "        executions_per_trial=1, \n",
    "        seed = 47,\n",
    "        directory=f'gru_tuning_{linea}_{target}',\n",
    "        project_name=f'gru_tuning_timeseries_{linea}_{target}')\n",
    "\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_wape_metric', \n",
    "        patience=7, \n",
    "        restore_best_weights=True,\n",
    "        mode = \"min\" \n",
    "    )\n",
    "    # Búsqueda de hiperparámetros\n",
    "    tuner.search(\n",
    "        X_train_seq, \n",
    "        y_train_seq, \n",
    "        epochs=20, \n",
    "        validation_split=0.2, \n",
    "        batch_size=32,\n",
    "        callbacks=[early_stopping] )\n",
    "    best_model = tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "    best_model.fit(X_train_seq, y_train_seq, epochs=80, validation_split=0.2, batch_size=32)\n",
    "\n",
    "    y_pred_gru_tuned = best_model.predict(nuevos_periodos)\n",
    "    y_pred_gru_tuned_rescaled = scaler_y.inverse_transform(y_pred_gru_tuned)\n",
    "\n",
    "    return y_pred_gru_tuned_rescaled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nuevas_predicciones(mejor_modelo, df,linea,target,diccionario,festivos, llamadas_futuras):\n",
    "    datos = df[df[\"linea\"]== linea].reset_index(drop=True)\n",
    "    datos_prophet = datos[[\"fecha\", target]].rename(columns={\"fecha\": 'ds', target: 'y'})\n",
    "    state_holidays = datos[datos['state_holiday'] == 1][\"fecha\"].unique()\n",
    "    state_holidays = pd.DataFrame({'ds': pd.to_datetime(state_holidays), 'holiday': 'state_holiday'})\n",
    "    n_fecha = (pd.Timestamp('2024-12-31') - pd.to_datetime(df[\"fecha\"]).max()).days\n",
    "    nuevos_periodos = pd.DataFrame({\n",
    "        \"fecha\": pd.date_range(start=df[\"fecha\"].max(), periods=n_fecha + 1, freq='D')\n",
    "    })\n",
    "\n",
    "    nuevos_periodos[\"año\"] = nuevos_periodos[\"fecha\"].dt.year\n",
    "    nuevos_periodos[\"mes\"] = nuevos_periodos[\"fecha\"].dt.month\n",
    "    nuevos_periodos[\"dia\"] = nuevos_periodos[\"fecha\"].dt.day\n",
    "    nuevos_periodos[\"dia_semana\"] = nuevos_periodos[\"fecha\"].dt.weekday\n",
    "\n",
    "\n",
    "    fes_filtrado = festivos[[\"fecha\", \"state_holiday\"]]\n",
    "    nuevos_periodos = pd.merge(nuevos_periodos, fes_filtrado, how=\"left\", on=\"fecha\")\n",
    "    nuevos_periodos[\"state_holiday\"].fillna(0, inplace=True)\n",
    "    nuevos_periodos.loc[nuevos_periodos['state_holiday'] == 1, 'dia_semana'] = 7\n",
    "\n",
    "    nuevos_periodos=nuevos_periodos.set_index(pd.RangeIndex(start=datos.index[-1]+1, stop=datos.index[-1]+1+len(nuevos_periodos), step=1))[[\"año\",\"mes\",\"dia\",\"dia_semana\",'state_holiday']]\n",
    "\n",
    "    if target == \"interpolado_real_aht\":\n",
    "        llamadas_futuras=llamadas_futuras[llamadas_futuras[\"linea\"]== linea].reset_index(drop=True)\n",
    "        nuevos_periodos[\"interpolado_real_calls\"]=llamadas_futuras[\"interpolado_real_calls\"].values\n",
    "\n",
    "    nuevos_periodos = nuevos_periodos.sort_values(by=[\"año\", \"mes\", \"dia\", \"dia_semana\"])\n",
    "\n",
    "    \n",
    "\n",
    "    if mejor_modelo == \"pred_regr\":\n",
    "        modelo_dic= diccionario[linea][\"pycaret_reg\"]\n",
    "        if'catboost' in str(modelo_dic[\"modelo\"]):\n",
    "            modelo = CatBoostRegressor()\n",
    "        else: \n",
    "            modelo = modelo_dic[\"modelo\"]\n",
    "        modelo_reg =modelo.set_params(**modelo_dic[\"parametros\"])\n",
    "        if target == \"interpolado_real_calls\":\n",
    "            datos = datos[['año', 'mes', \"dia\", 'dia_semana', 'state_holiday',target]].dropna()\n",
    "            X, Y= datos[['año', 'mes', \"dia\", 'dia_semana', 'state_holiday']],datos[target]\n",
    "        else:\n",
    "            datos = datos[['año', 'mes', \"dia\", 'dia_semana', 'state_holiday',\"interpolado_real_calls\",target]].dropna()\n",
    "            X, Y= datos[['año', 'mes', \"dia\", 'dia_semana', 'state_holiday',\"interpolado_real_calls\"]],datos[target]\n",
    "\n",
    "\n",
    "        pred = modelo_reg.fit(X, Y).predict(nuevos_periodos)\n",
    "        nuevos_periodos[\"prediccion\"]=pred\n",
    "    \n",
    "    elif mejor_modelo ==\"pred_ts\":\n",
    "        modelo_dic= diccionario[linea][\"pycaret_ts\"]\n",
    "        modelo =modelo_dic[\"modelo\"].set_params(**modelo_dic[\"parametros\"])\n",
    "        if target == \"interpolado_real_calls\":\n",
    "            datos = datos[['año', 'mes', \"dia\", 'dia_semana', 'state_holiday',target]].dropna()\n",
    "            X, Y= datos[['año', 'mes', \"dia\", 'dia_semana', 'state_holiday']],datos[target]\n",
    "        else:\n",
    "            datos = datos[['año', 'mes', \"dia\", 'dia_semana', 'state_holiday',\"interpolado_real_calls\",target]].dropna()\n",
    "            X, Y= datos[['año', 'mes', \"dia\", 'dia_semana', 'state_holiday',\"interpolado_real_calls\"]],datos[target]\n",
    "        \n",
    "        fh = ForecastingHorizon(range(1, len(nuevos_periodos)+1))\n",
    "        pred = modelo.fit(X = X, y = Y).predict(X =nuevos_periodos,fh=fh)\n",
    "        \n",
    "        nuevos_periodos[\"prediccion\"]=pred\n",
    "\n",
    "    elif mejor_modelo== \"pred_promedio\":\n",
    "        modelo_dic_reg= diccionario[linea][\"pycaret_reg\"]\n",
    "        if'catboost' in str(modelo_dic_reg[\"modelo\"]):\n",
    "            modelo = CatBoostRegressor()\n",
    "        else: \n",
    "            modelo = modelo_dic_reg[\"modelo\"]\n",
    "        modelo_reg =modelo.set_params(**modelo_dic_reg[\"parametros\"])\n",
    "        if target == \"interpolado_real_calls\":\n",
    "            datos = datos[['año', 'mes', \"dia\", 'dia_semana', 'state_holiday',target]].dropna()\n",
    "            X, Y= datos[['año', 'mes', \"dia\", 'dia_semana', 'state_holiday']],datos[target]\n",
    "        else:\n",
    "            datos = datos[['año', 'mes', \"dia\", 'dia_semana', 'state_holiday',\"interpolado_real_calls\",target]].dropna()\n",
    "            X, Y= datos[['año', 'mes', \"dia\", 'dia_semana', 'state_holiday',\"interpolado_real_calls\"]],datos[target]\n",
    "\n",
    "        pred_reg = modelo_reg.fit(X, Y).predict(nuevos_periodos)\n",
    "\n",
    "        modelo_dic_ts= diccionario_calls[\"linea_1\"][\"pycaret_ts\"]\n",
    "        modelo_ts =modelo_dic_ts[\"modelo\"].set_params(**modelo_dic_ts[\"parametros\"])\n",
    "        fh = ForecastingHorizon(range(1, len(nuevos_periodos)+1))\n",
    "        pred_ts = modelo_ts.fit(X = X, y = Y).predict(X =nuevos_periodos,fh=fh)\n",
    "\n",
    "        nuevos_periodos[\"prediccion\"]=(pred_reg + pred_ts)/2\n",
    "\n",
    "    elif mejor_modelo == \"pred_fb\":\n",
    "        prophet_params= diccionario[linea][\"prophet\"]\n",
    "        model = Prophet(holidays=state_holidays, **prophet_params)\n",
    "        model.fit(datos_prophet)\n",
    "        future = model.make_future_dataframe(periods=len(nuevos_periodos), freq='D')\n",
    "        forecast = model.predict(future)\n",
    "        nuevos_periodos[\"prediccion\"]=forecast[\"yhat\"][-len(nuevos_periodos):]\n",
    "\n",
    "    elif mejor_modelo == \"pred_gru\":\n",
    "        nuevos_periodos[\"prediccion\"] = entrenamiento_gru(datos,target,linea,nuevos_periodos)\n",
    "    \n",
    "                \n",
    "    if(linea == \"lines_3\"): \n",
    "        nuevos_periodos.loc[nuevos_periodos['dia_semana'] == 6, 'prediccion'] = 0\n",
    "        \n",
    "        \n",
    "    nuevos_periodos[\"linea\"]=linea\n",
    "\n",
    "    return nuevos_periodos\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linea_1\n",
      "pred_ts\n",
      "linea_2\n",
      "pred_ts\n",
      "linea_3\n",
      "pred_regr\n",
      "linea_4\n",
      "pred_promedio\n",
      "linea_5\n",
      "pred_regr\n"
     ]
    }
   ],
   "source": [
    "lineas = entrenamiento_calls['linea'].unique()\n",
    "wape_metrics_calls = {}\n",
    "pred_calls=pd.DataFrame()\n",
    "\n",
    "for linea in lineas:\n",
    "    print(linea)\n",
    "    df_linea = entrenamiento_calls[entrenamiento_calls['linea'] == linea]\n",
    "    y_true = df_linea['interpolado_real_calls']\n",
    "    pred_columns = ['pred_ts', 'pred_regr', 'pred_promedio', 'pred_fb', 'pred_gru']\n",
    "\n",
    "    wape_metrics_calls[linea] = {col: round(wape(y_true, df_linea[col]),2) for col in pred_columns}\n",
    "    mejor_modelo = min(wape_metrics_calls[linea], key=wape_metrics_calls[linea].get)\n",
    "    print(mejor_modelo)\n",
    "    predicciones_calls=nuevas_predicciones(mejor_modelo, df,linea,\"interpolado_real_calls\",diccionario_calls,festivos,None)\n",
    "    pred_calls=pd.concat([pred_calls,predicciones_calls])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_calls.to_excel(\"prediccion_calls.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linea_1\n",
      "pred_promedio\n",
      "linea_2\n",
      "pred_regr\n",
      "linea_3\n",
      "pred_ts\n",
      "linea_4\n",
      "pred_fb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01:14:53 - cmdstanpy - INFO - Chain [1] start processing\n",
      "01:14:53 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linea_5\n",
      "pred_regr\n"
     ]
    }
   ],
   "source": [
    "llamadas_futuras =pred_calls[[\"prediccion\",\"linea\"]].reset_index(drop=True)\n",
    "llamadas_futuras.rename(columns={'prediccion': 'interpolado_real_calls'}, inplace=True)\n",
    "\n",
    "lineas = entrenamiento_aht['linea'].unique()\n",
    "wape_metrics_aht = {}\n",
    "pred_aht=pd.DataFrame()\n",
    "\n",
    "for linea in lineas:\n",
    "    print(linea)\n",
    "    df_linea = entrenamiento_aht[entrenamiento_aht['linea'] == linea]\n",
    "    y_true = df_linea['interpolado_real_aht']\n",
    "    pred_columns = ['pred_ts', 'pred_regr', 'pred_promedio', 'pred_fb', 'pred_gru']\n",
    "\n",
    "    wape_metrics_aht[linea] = {col: round(wape(y_true, df_linea[col]),2) for col in pred_columns}\n",
    "    mejor_modelo = min(wape_metrics_aht[linea], key=wape_metrics_aht[linea].get)\n",
    "    print(mejor_modelo)\n",
    "    predicciones_aht= nuevas_predicciones(mejor_modelo,df,linea,\"interpolado_real_aht\",diccionario_aht,festivos,llamadas_futuras)\n",
    "    pred_aht=pd.concat([pred_aht,predicciones_aht])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_aht.to_excel(\"prediccion_aht.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfm_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
